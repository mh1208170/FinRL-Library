{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "FinRL_single_stock_trading.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "Y9CM5DeIr9GC",
    "9upN8FI2r_X1",
    "CiBG2ZknsG73"
   ],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "#install finrl library\n",
     "import finrl\n",
     "from finrl.env.env_cfdtrading import TradingEnv\n",
     "!pip3 install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
     "!pip3 install pandas"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gr/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from finrl.env.env_cfdtrading import TradingEnv\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "from finrl.trade.backtest import BackTestStats, BaselineStats, BackTestPlot\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import quantstats as qs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uIPbzYs1TnSd"
   },
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pos2IZAL54pp"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zp6lL6dZ53rX"
   },
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBPM0sVvTnSg"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCGVmtGzjORf"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FBEiH5gOgMOx",
    "outputId": "de388576-0110-46f4-9257-dfe327b3eac5"
   },
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'2009-01-01'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "sWLMNQ8CgMRx",
    "outputId": "f1864c8b-2b5c-4867-9122-ccf83ebc2902"
   },
   "source": [
    "# from config.py end_date is a string\n",
    "config.END_DATE"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'2020-12-01'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmFpuBEZhkF3"
   },
   "source": [
    "ticker_list is a list of stock tickers, in a single stock trading case, the list contains only 1 ticker"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtIFikNyTnSg",
    "outputId": "4c6a860f-6944-4728-984d-d0dc8d8f2c78"
   },
   "source": [
    "# Download and save the data in a pandas DataFrame:\n",
    "data_df = YahooDownloader(start_date = '2009-01-01',\n",
    "                          end_date = '2021-01-01',\n",
    "                          ticker_list = ['AAPL']).fetch_data()"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3022, 7)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8ZKQmw6TnSl",
    "outputId": "954cbef4-f75b-4d4b-80f2-195eb13954ef"
   },
   "source": [
    "data_df.shape"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(3022, 7)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Vi6D_ED6TnSs",
    "outputId": "2313cd51-596f-4a58-922b-5ec837bbcbda"
   },
   "source": [
    "data_df.head()"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "         date      open      high       low     close      volume   tic\n0  2008-12-31  3.070357  3.133571  3.047857  2.629544   607541200  AAPL\n1  2009-01-02  3.067143  3.251429  3.041429  2.795913   746015200  AAPL\n2  2009-01-05  3.327500  3.435000  3.311071  2.913912  1181608400  AAPL\n3  2009-01-06  3.426786  3.470357  3.299643  2.865849  1289310400  AAPL\n4  2009-01-07  3.278929  3.303571  3.223572  2.803923   753048800  AAPL",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>tic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-12-31</td>\n      <td>3.070357</td>\n      <td>3.133571</td>\n      <td>3.047857</td>\n      <td>2.629544</td>\n      <td>607541200</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-01-02</td>\n      <td>3.067143</td>\n      <td>3.251429</td>\n      <td>3.041429</td>\n      <td>2.795913</td>\n      <td>746015200</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-01-05</td>\n      <td>3.327500</td>\n      <td>3.435000</td>\n      <td>3.311071</td>\n      <td>2.913912</td>\n      <td>1181608400</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-01-06</td>\n      <td>3.426786</td>\n      <td>3.470357</td>\n      <td>3.299643</td>\n      <td>2.865849</td>\n      <td>1289310400</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-01-07</td>\n      <td>3.278929</td>\n      <td>3.303571</td>\n      <td>3.223572</td>\n      <td>2.803923</td>\n      <td>753048800</td>\n      <td>AAPL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWiqgpLzTnS3"
   },
   "source": [
    "<a id='3'></a>\n",
    "# Part 4. Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* FinRL uses a class **FeatureEngineer** to preprocess the data\n",
    "* Add **technical indicators**. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ9zmxpRks41"
   },
   "source": [
    "class FeatureEngineer:\n",
    "Provides methods for preprocessing the stock price data\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            data downloaded from Yahoo API\n",
    "        feature_number : int\n",
    "            number of features we used\n",
    "        use_technical_indicator : boolean\n",
    "            we technical indicator or not\n",
    "        use_turbulence : boolean\n",
    "            use turbulence index or not\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess_data()\n",
    "        main method to do the feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHu7i-T_wRPc"
   },
   "source": [
    "<a id='3.1'></a>\n",
    "\n",
    "## 4.1 Technical Indicators\n",
    "* FinRL uses stockstats to calcualte technical indicators such as **Moving Average Convergence Divergence (MACD)**, **Relative Strength Index (RSI)**, **Average Directional Index (ADX)**, **Commodity Channel Index (CCI)** and other various indicators and stats.\n",
    "* **stockstats**: supplies a wrapper StockDataFrame based on the **pandas.DataFrame** with inline stock statistics/indicators support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RHwY1dHk09N",
    "outputId": "47be0df8-9e74-473e-f78e-9f267bcce3df"
   },
   "source": [
    "## we store the stockstats technical indicator column names in config.py\n",
    "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
    "print(tech_indicator_list)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['macd', 'rsi_30', 'cci_30', 'dx_30']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rImfGAfCkR8j",
    "outputId": "5b55c2c7-3217-49ad-95b7-d9af0ad91d7a"
   },
   "source": [
    "## user can add more technical indicators\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "tech_indicator_list=tech_indicator_list+['kdjk','open_2_sma','boll','close_10.0_le_5_c','wr_10','dma','trix']\n",
    "print(tech_indicator_list)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['macd', 'rsi_30', 'cci_30', 'dx_30', 'kdjk', 'open_2_sma', 'boll', 'close_10.0_le_5_c', 'wr_10', 'dma', 'trix']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etvRo2rSwZPg"
   },
   "source": [
    "<a id='3.2'></a>\n",
    "## 4.2 Perform Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAOsx0m-9u2k",
    "outputId": "6238a0f8-e0bb-4468-ec75-ab3381ea09a9"
   },
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = tech_indicator_list,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "data_df = fe.preprocess_data(data_df)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "wytX_qwWMHP5",
    "outputId": "8113269b-39a0-462b-80b2-b8664eb27a66"
   },
   "source": [
    "data_df.head()"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "         date      open      high       low     close      volume   tic  \\\n0  2008-12-31  3.070357  3.133571  3.047857  2.629544   607541200  AAPL   \n1  2009-01-02  3.067143  3.251429  3.041429  2.795913   746015200  AAPL   \n2  2009-01-05  3.327500  3.435000  3.311071  2.913912  1181608400  AAPL   \n3  2009-01-06  3.426786  3.470357  3.299643  2.865849  1289310400  AAPL   \n4  2009-01-07  3.278929  3.303571  3.223572  2.803923   753048800  AAPL   \n\n       macd      rsi_30      cci_30       dx_30        kdjk  open_2_sma  \\\n0  0.000000  100.000000   66.666667  100.000000 -129.343666    3.070357   \n1  0.003733  100.000000   66.666667  100.000000 -125.199831    3.068750   \n2  0.008415  100.000000  100.000000  100.000000  -94.266522    3.197322   \n3  0.008603   84.866549   64.361783  100.000000  -76.489126    3.377143   \n4  0.006060   70.621407    6.034007   58.463049  -69.449994    3.352857   \n\n       boll  close_10.0_le_5_c       wr_10  dma      trix  \n0  2.629544                1.0  588.030998  0.0  1.005511  \n1  2.712729                2.0  216.912162  0.0  1.005511  \n2  2.779790                3.0  132.399904  0.0  1.000508  \n3  2.801305                4.0  140.934334  0.0  0.836218  \n4  2.801828                5.0  155.371731  0.0  0.653105  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>tic</th>\n      <th>macd</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>kdjk</th>\n      <th>open_2_sma</th>\n      <th>boll</th>\n      <th>close_10.0_le_5_c</th>\n      <th>wr_10</th>\n      <th>dma</th>\n      <th>trix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-12-31</td>\n      <td>3.070357</td>\n      <td>3.133571</td>\n      <td>3.047857</td>\n      <td>2.629544</td>\n      <td>607541200</td>\n      <td>AAPL</td>\n      <td>0.000000</td>\n      <td>100.000000</td>\n      <td>66.666667</td>\n      <td>100.000000</td>\n      <td>-129.343666</td>\n      <td>3.070357</td>\n      <td>2.629544</td>\n      <td>1.0</td>\n      <td>588.030998</td>\n      <td>0.0</td>\n      <td>1.005511</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2009-01-02</td>\n      <td>3.067143</td>\n      <td>3.251429</td>\n      <td>3.041429</td>\n      <td>2.795913</td>\n      <td>746015200</td>\n      <td>AAPL</td>\n      <td>0.003733</td>\n      <td>100.000000</td>\n      <td>66.666667</td>\n      <td>100.000000</td>\n      <td>-125.199831</td>\n      <td>3.068750</td>\n      <td>2.712729</td>\n      <td>2.0</td>\n      <td>216.912162</td>\n      <td>0.0</td>\n      <td>1.005511</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009-01-05</td>\n      <td>3.327500</td>\n      <td>3.435000</td>\n      <td>3.311071</td>\n      <td>2.913912</td>\n      <td>1181608400</td>\n      <td>AAPL</td>\n      <td>0.008415</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>-94.266522</td>\n      <td>3.197322</td>\n      <td>2.779790</td>\n      <td>3.0</td>\n      <td>132.399904</td>\n      <td>0.0</td>\n      <td>1.000508</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009-01-06</td>\n      <td>3.426786</td>\n      <td>3.470357</td>\n      <td>3.299643</td>\n      <td>2.865849</td>\n      <td>1289310400</td>\n      <td>AAPL</td>\n      <td>0.008603</td>\n      <td>84.866549</td>\n      <td>64.361783</td>\n      <td>100.000000</td>\n      <td>-76.489126</td>\n      <td>3.377143</td>\n      <td>2.801305</td>\n      <td>4.0</td>\n      <td>140.934334</td>\n      <td>0.0</td>\n      <td>0.836218</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2009-01-07</td>\n      <td>3.278929</td>\n      <td>3.303571</td>\n      <td>3.223572</td>\n      <td>2.803923</td>\n      <td>753048800</td>\n      <td>AAPL</td>\n      <td>0.006060</td>\n      <td>70.621407</td>\n      <td>6.034007</td>\n      <td>58.463049</td>\n      <td>-69.449994</td>\n      <td>3.352857</td>\n      <td>2.801828</td>\n      <td>5.0</td>\n      <td>155.371731</td>\n      <td>0.0</td>\n      <td>0.653105</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLhXo1cTnTQ"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Build Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D1FlBdOL4b3"
   },
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1 Training & Trade data split\n",
    "* Training: 2009-01-01 to 2018-12-31\n",
    "* Trade: 2019-01-01 to 2020-09-30"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xNOdqfTKL6K-"
   },
   "source": [
    "#train = data_split(data_df, start = config.START_DATE, end = config.START_TRADE_DATE)\n",
    "#trade = data_split(data_df, start = config.START_TRADE_DATE, end = config.END_DATE)\n",
    "train = data_split(data_df, start = '2009-01-01', end = '2019-01-01')\n",
    "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KUxOshVouLXt"
   },
   "source": [
    "## data normalization, this part is optional, have little impact\n",
    "#feaures_list = list(train.columns)\n",
    "#feaures_list.remove('date')\n",
    "#feaures_list.remove('tic')\n",
    "#feaures_list.remove('close')\n",
    "#print(feaures_list)\n",
    "#from sklearn import preprocessing\n",
    "#data_normaliser = preprocessing.StandardScaler()\n",
    "#train[feaures_list] = data_normaliser.fit_transform(train[feaures_list])\n",
    "#trade[feaures_list] = data_normaliser.transform(trade[feaures_list])"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMHyaSBBDGbe"
   },
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2 User-defined Environment: a simulation environment class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90V3S7cpDcQs"
   },
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3 Initialize Environment\n",
    "* **stock dimension**: the number of unique stock tickers we use\n",
    "* **hmax**: the maximum amount of shares to buy or sell\n",
    "* **initial amount**: the amount of money we use to trade in the begining\n",
    "* **transaction cost percentage**: a per share rate for every share trade\n",
    "* **tech_indicator_list**: a list of technical indicator names (modified from config.py)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiH0xO96mGcL",
    "outputId": "490190d9-80dd-4ba0-c15f-2143cdd8341f"
   },
   "source": [
    "## we store the stockstats technical indicator column names in config.py\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "tech_indicator_list"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['macd',\n 'rsi_30',\n 'cci_30',\n 'dx_30',\n 'kdjk',\n 'open_2_sma',\n 'boll',\n 'close_10.0_le_5_c',\n 'wr_10',\n 'dma',\n 'trix']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnWOKS7DyGM7",
    "outputId": "09dff84b-19e1-4c4a-c40f-d5280195eaf4"
   },
   "source": [
    "# the stock dimension is 1, because we only use the price data of AAPL.\n",
    "len(train.tic.unique())"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipJcnLvQGAba",
    "outputId": "dc32ebc6-2191-4541-99d2-7e9861da5df6"
   },
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 7\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JY5wTwYjGTrg"
   },
   "source": [
    "import finrl\n",
    "import gym\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 100000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "df = finrl.datasets.STOCKS_GOOGL.copy()\n",
    "window_size = 10\n",
    "start_index = window_size\n",
    "end_index = len(df)\n",
    "frame_bound = (start_index, end_index)\n",
    "e_train_gym = TradingEnv(df=df,amount=25,leverage=100, window_size=window_size,frame_bound=frame_bound)\n"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vmyi2IPnyEkP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a968a96a-a1ee-426e-eed8-ee74d20b9bb8"
   },
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "\n",
    "#env_train, _ = e_train_gym.get_sb_env()\n",
    "#print(type(env_train))"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdnzYtM1TnTW"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BRFIZDw8TnTX"
   },
   "source": [
    "agent = DRLAgent(env = env_train)"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD1NHzGyTnTc"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CM5DeIr9GC"
   },
   "source": [
    "### Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOk-Mr73-EEq",
    "outputId": "1c56a5c6-91ad-4b81-dd07-24ae69e64c23"
   },
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cuda device\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXHEidJh-E60",
    "outputId": "9ae1ede1-a8ee-4e56-c4f3-ef809e05d664"
   },
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/a2c/a2c_6\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.31    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 3.98     |\n",
      "|    value_loss         | 25.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0892  |\n",
      "|    value_loss         | 0.00327  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.0605  |\n",
      "|    value_loss         | 0.00239  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 528       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.12     |\n",
      "|    explained_variance | -1.69e+14 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 3.15      |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0458  |\n",
      "|    value_loss         | 0.00438  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.0972  |\n",
      "|    value_loss         | 0.0046   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.0686  |\n",
      "|    value_loss         | 0.00463  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 523      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 522      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.968   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0385  |\n",
      "|    value_loss         | 0.00647  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.954   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 10.1     |\n",
      "|    value_loss         | 361      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.959   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.114   |\n",
      "|    value_loss         | 0.0073   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.944   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.0513  |\n",
      "|    value_loss         | 0.00769  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.946   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.126   |\n",
      "|    value_loss         | 0.00809  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 517      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.972   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    value_loss         | 0.737    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1       |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 6.1      |\n",
      "|    value_loss         | 74.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.987   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.0659  |\n",
      "|    value_loss         | 0.00913  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.943   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 3.67     |\n",
      "|    value_loss         | 46.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.942   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.0852  |\n",
      "|    value_loss         | 0.00627  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.933   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.0534  |\n",
      "|    value_loss         | 0.00924  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 521      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.92    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 4.41     |\n",
      "|    value_loss         | 27.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 522      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.895   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0915  |\n",
      "|    value_loss         | 0.013    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 524       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.858    |\n",
      "|    explained_variance | -4.34e+10 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -0.0996   |\n",
      "|    value_loss         | 0.0138    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.824   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.0556  |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 524      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.86    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.121   |\n",
      "|    value_loss         | 0.0149   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 525      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.856   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 3.41     |\n",
      "|    value_loss         | 50.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 526      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.842   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 2.46     |\n",
      "|    value_loss         | 4.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.826   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.952    |\n",
      "|    value_loss         | 19       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 527      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.857   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.678    |\n",
      "|    value_loss         | 2.79     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.842   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.134   |\n",
      "|    value_loss         | 0.0225   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 528      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.845   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.0993  |\n",
      "|    value_loss         | 0.0271   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.856   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 3.81     |\n",
      "|    value_loss         | 38.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.856   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.127   |\n",
      "|    value_loss         | 0.0251   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.854   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.324   |\n",
      "|    value_loss         | 0.0297   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.849   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 12.9     |\n",
      "|    value_loss         | 117      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.824   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.141   |\n",
      "|    value_loss         | 0.0324   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.813   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 1.91     |\n",
      "|    value_loss         | 16.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.813   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.262   |\n",
      "|    value_loss         | 0.0414   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.797   |\n",
      "|    explained_variance | -3.6e+10 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    value_loss         | 0.046    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.783   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 3.68     |\n",
      "|    value_loss         | 36.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 530       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.783    |\n",
      "|    explained_variance | -2.05e+13 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 1.18      |\n",
      "|    value_loss         | 7.29      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 529       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.784    |\n",
      "|    explained_variance | -4.25e+10 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -0.135    |\n",
      "|    value_loss         | 0.0542    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 529       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.775    |\n",
      "|    explained_variance | -9.33e+10 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 1.7       |\n",
      "|    value_loss         | 7.56      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.762   |\n",
      "|    explained_variance | -4.6e+10 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.171   |\n",
      "|    value_loss         | 0.0586   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.787   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 2.87     |\n",
      "|    value_loss         | 17.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.785   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 2.65     |\n",
      "|    value_loss         | 22.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.777   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.163   |\n",
      "|    value_loss         | 0.0739   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.796   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.182   |\n",
      "|    value_loss         | 0.0745   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.786   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 0.0762   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.792   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 1.65     |\n",
      "|    value_loss         | 72.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.809   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.162   |\n",
      "|    value_loss         | 0.0758   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.795   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.166   |\n",
      "|    value_loss         | 0.0742   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.789   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.147   |\n",
      "|    value_loss         | 0.0617   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.771   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.169   |\n",
      "|    value_loss         | 0.0721   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.718   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    value_loss         | 5.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.743   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.719    |\n",
      "|    value_loss         | 1.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.762   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.153   |\n",
      "|    value_loss         | 0.0789   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.766   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.0185  |\n",
      "|    value_loss         | 0.175    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.781   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 3.89     |\n",
      "|    value_loss         | 47       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.758   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.206   |\n",
      "|    value_loss         | 0.0861   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.784   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 6.1      |\n",
      "|    value_loss         | 145      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.784   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.959    |\n",
      "|    value_loss         | 4.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.791   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 3.45     |\n",
      "|    value_loss         | 7.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.778   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.15    |\n",
      "|    value_loss         | 0.0929   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 529      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.793   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 4.76     |\n",
      "|    value_loss         | 149      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.793   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -0.202   |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.81    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -0.228   |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.796   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.199   |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.812   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.376    |\n",
      "|    value_loss         | 1.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.811   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    value_loss         | 7.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.82    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -0.181   |\n",
      "|    value_loss         | 0.101    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.775   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.195   |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.807   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 0.802    |\n",
      "|    value_loss         | 2.55     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.819   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.726    |\n",
      "|    value_loss         | 9.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.806   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 23.1     |\n",
      "|    value_loss         | 320      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.76    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -0.213   |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.776   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 3.81     |\n",
      "|    value_loss         | 68.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.817   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -0.375   |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.832   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.0504   |\n",
      "|    value_loss         | 0.678    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 530      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.818   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 3.1      |\n",
      "|    value_loss         | 20.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.845   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.818   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 2.25     |\n",
      "|    value_loss         | 23       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.805   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 1.21     |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.811   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 5.44     |\n",
      "|    value_loss         | 138      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.808   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.227   |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.797   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    value_loss         | 5.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.79    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.189   |\n",
      "|    value_loss         | 0.113    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.741   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 0.638    |\n",
      "|    value_loss         | 1.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.797   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 13       |\n",
      "|    value_loss         | 482      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.79    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | -0.226   |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.763   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.0178   |\n",
      "|    value_loss         | 0.477    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.772   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 0.867    |\n",
      "|    value_loss         | 2.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.785   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 6.63     |\n",
      "|    value_loss         | 88.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.778   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.26    |\n",
      "|    value_loss         | 0.116    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.783   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -0.257   |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.749   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 3.89     |\n",
      "|    value_loss         | 45.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.706   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.107   |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.759   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.145   |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.784   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 3.87     |\n",
      "|    value_loss         | 39.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 532      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 93       |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.797   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.962    |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 531      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.801   |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.249    |\n",
      "|    value_loss         | 2.81     |\n",
      "------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9upN8FI2r_X1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUFJlHsi-Ka-",
    "outputId": "1b7db70f-f740-401c-ab55-a567b4235e18"
   },
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 64, \"buffer_size\": 500000, \"learning_rate\": 0.0001}\n",
    "\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'buffer_size': 500000, 'learning_rate': 0.0001}\n",
      "Using cuda device\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5J_Scwp-Nis",
    "outputId": "a538962d-33c8-44d3-94af-6ef61fc0d230"
   },
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=10000)"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/ddpg/ddpg_5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"normal_kernel_cuda\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-e7b8a6f6eb72>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m trained_ddpg = agent.train_model(model=model_ddpg, \n\u001B[1;32m      2\u001B[0m                              \u001B[0mtb_log_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'ddpg'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m                              total_timesteps=10000)\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/FinRL-Library/finrl/model/models.py\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(self, model, tb_log_name, total_timesteps)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_log_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal_timesteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtotal_timesteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtotal_timesteps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_log_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtb_log_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/stable_baselines3/ddpg/ddpg.py\u001B[0m in \u001B[0;36mlearn\u001B[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001B[0m\n\u001B[1;32m    133\u001B[0m             \u001B[0mtb_log_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtb_log_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m             \u001B[0meval_log_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0meval_log_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 135\u001B[0;31m             \u001B[0mreset_num_timesteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreset_num_timesteps\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    136\u001B[0m         )\n",
      "\u001B[0;32m~/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/stable_baselines3/td3/td3.py\u001B[0m in \u001B[0;36mlearn\u001B[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001B[0m\n\u001B[1;32m    203\u001B[0m             \u001B[0mtb_log_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtb_log_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m             \u001B[0meval_log_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0meval_log_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 205\u001B[0;31m             \u001B[0mreset_num_timesteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreset_num_timesteps\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    206\u001B[0m         )\n\u001B[1;32m    207\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001B[0m in \u001B[0;36mlearn\u001B[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001B[0m\n\u001B[1;32m    267\u001B[0m                 \u001B[0;31m# do as many gradients steps as steps performed during the rollout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m                 \u001B[0mgradient_steps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient_steps\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient_steps\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mrollout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepisode_timesteps\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 269\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient_steps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgradient_steps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    270\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    271\u001B[0m         \u001B[0mcallback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_training_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/stable_baselines3/td3/td3.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, gradient_steps, batch_size)\u001B[0m\n\u001B[1;32m    141\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mth\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                 \u001B[0;31m# Select action according to policy and add clipped noise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 143\u001B[0;31m                 \u001B[0mnoise\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreplay_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormal_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_policy_noise\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    144\u001B[0m                 \u001B[0mnoise\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnoise\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_noise_clip\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_noise_clip\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m                 \u001B[0mnext_actions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactor_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreplay_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnext_observations\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mnoise\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \"normal_kernel_cuda\" not implemented for 'Long'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sve9WGvsC__"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOjuycpS-Qvn",
    "outputId": "13ab0019-419b-4e6e-949d-c2617ae296b3"
   },
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9hCHA8A-RSy",
    "outputId": "df865883-f3a8-42b2-951f-b129b44bd248"
   },
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=80000)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiBG2ZknsG73"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcRdoBc8-Xze",
    "outputId": "cc0a65bf-f79d-48ce-c173-6ae08747b0fa"
   },
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 128, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.0003}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0003}\n",
      "Using cuda device\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB5cAAio-ZSs",
    "outputId": "741a1ed9-9bb0-4763-f237-5cd461ac100e"
   },
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/td3/td3_2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"normal_kernel_cuda\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-9e1d8767924b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m trained_td3 = agent.train_model(model=model_td3, \n\u001B[1;32m      2\u001B[0m                              \u001B[0mtb_log_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'td3'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m                              total_timesteps=30000)\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/FinRL-Library/finrl/model/models.py\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(self, model, tb_log_name, total_timesteps)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_log_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtotal_timesteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtotal_timesteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtotal_timesteps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_log_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtb_log_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/stable_baselines3/td3/td3.py\u001B[0m in \u001B[0;36mlearn\u001B[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001B[0m\n\u001B[1;32m    203\u001B[0m             \u001B[0mtb_log_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtb_log_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m             \u001B[0meval_log_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0meval_log_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 205\u001B[0;31m             \u001B[0mreset_num_timesteps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreset_num_timesteps\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    206\u001B[0m         )\n\u001B[1;32m    207\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001B[0m in \u001B[0;36mlearn\u001B[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001B[0m\n\u001B[1;32m    267\u001B[0m                 \u001B[0;31m# do as many gradients steps as steps performed during the rollout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m                 \u001B[0mgradient_steps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient_steps\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient_steps\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mrollout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepisode_timesteps\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 269\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient_steps\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mgradient_steps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    270\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    271\u001B[0m         \u001B[0mcallback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_training_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FinRL-Library/lib/python3.6/site-packages/stable_baselines3/td3/td3.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, gradient_steps, batch_size)\u001B[0m\n\u001B[1;32m    141\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mth\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m                 \u001B[0;31m# Select action according to policy and add clipped noise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 143\u001B[0;31m                 \u001B[0mnoise\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreplay_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclone\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormal_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_policy_noise\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    144\u001B[0m                 \u001B[0mnoise\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnoise\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_noise_clip\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget_noise_clip\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m                 \u001B[0mnext_actions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactor_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreplay_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnext_observations\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mnoise\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclamp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: \"normal_kernel_cuda\" not implemented for 'Long'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDk2qrlTLZCp"
   },
   "source": [
    "### Model 4: SAC"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "el8sK4fo-dl1",
    "outputId": "20c5793c-397b-4dc3-a702-857178e61813"
   },
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.00003,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 3e-05, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaF80PR0-d_d",
    "outputId": "b26b6435-ca69-4000-b2b3-22596677d8ff"
   },
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=30000)"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/sac/sac_2\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 77       |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total timesteps | 9296     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.95    |\n",
      "|    critic_loss     | 5.48     |\n",
      "|    ent_coef        | 0.132    |\n",
      "|    ent_coef_loss   | 7.2      |\n",
      "|    learning_rate   | 3e-05    |\n",
      "|    n_updates       | 9195     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 79       |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total timesteps | 18592    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 11.3     |\n",
      "|    critic_loss     | 29.2     |\n",
      "|    ent_coef        | 0.174    |\n",
      "|    ent_coef_loss   | 7.36     |\n",
      "|    learning_rate   | 3e-05    |\n",
      "|    n_updates       | 18491    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 79       |\n",
      "|    time_elapsed    | 349      |\n",
      "|    total timesteps | 27888    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35.9     |\n",
      "|    critic_loss     | 38       |\n",
      "|    ent_coef        | 0.229    |\n",
      "|    ent_coef_loss   | 5.88     |\n",
      "|    learning_rate   | 3e-05    |\n",
      "|    n_updates       | 27787    |\n",
      "---------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KE1Xm9N9TnTn"
   },
   "source": [
    "### Trading\n",
    "* we use the environment class we initialized at 5.3 to create a stock trading environment\n",
    "* Assume that we have $100,000 initial capital at 2019-01-01. \n",
    "* We use the trained model of PPO to trade AAPL."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "kLFUwxhCoHN_",
    "outputId": "22540921-fc5e-460b-f9ef-1438131b45d7"
   },
   "source": [
    "trade.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bLHl6V7eqV6_"
   },
   "source": [
    "## make a prediction and get the account value change\n",
    "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
    "e_trade_gym = TradingEnv(df=df,amount=25,leverage=100, window_size=window_size,frame_bound=frame_bound)\n",
    "env_trade, obs_trade= e_train_gym.get_sb_env()\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_sac,\n",
    "                                           test_data = trade,\n",
    "                                           test_env = env_trade,\n",
    "                                           test_obs = obs_trade)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYXxFzD5TnTw"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtesting Performance\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GwqOO-v1NVz"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9cpPm9YYxHC",
    "outputId": "7c7a8e34-7ed3-441d-9036-829240430843"
   },
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e-Tenjb0hcNr"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4Gw3HNr1TDU"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MA_8LuZE1J3X",
    "outputId": "3d2c46b2-2b6e-4cfd-9648-68ae7d37d89c"
   },
   "source": [
    "print(\"==============Compare to AAPL itself buy-and-hold===========\")\n",
    "%matplotlib inline\n",
    "BackTestPlot(account_value=df_account_value, \n",
    "             baseline_ticker = 'AAPL',\n",
    "             baseline_start = '2019-01-01',\n",
    "             baseline_end = '2021-01-01')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSFMdgCJE4O-"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MpR7aQIwqdC4",
    "outputId": "24029a71-3596-4090-d7bc-7f44dd6000fc"
   },
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baesline_perf_stats=BaselineStats('AAPL')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSFRXQfYFTQf",
    "outputId": "a5951bab-aa47-4fa8-9cd9-9fc62b5b02f5"
   },
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baesline_perf_stats=BaselineStats('^GSPC')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tunrA4mjE9la"
   },
   "source": [
    "<a id='6.4'></a>\n",
    "## 7.4 Compare to Stock Market Index"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5Ca2gHxi1gzX",
    "outputId": "68de7e8c-882a-4e8a-c9a9-cea8ea6ca212"
   },
   "source": [
    "print(\"==============Compare to S&P 500===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "BackTestPlot(df_account_value, baseline_ticker = '^GSPC')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3_aHGEOTCluG"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}